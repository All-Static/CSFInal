{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_train = r'C:\\Users\\Steven\\OneDrive - Cal State LA\\Documents\\train_metadata.json'\n",
    "with open(data_path_train) as json_file:\n",
    "    meta_train = json.load(json_file)\n",
    "    \n",
    "    \n",
    "#loading json file for test data\n",
    "data_path_test = r'C:\\Users\\Steven\\OneDrive - Cal State LA\\Documents\\test_metadata.json'\n",
    "with open(data_path_test) as json_file:\n",
    "    meta_test = json.load(json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['annotations', 'images', 'categories', 'genera', 'institutions', 'distances', 'license'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding keys in train dictionary\n",
    "meta_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating seperate dataframes from metadata\n",
    "annotations_train =  pd.json_normalize(meta_train ['annotations'])\n",
    "categories_train =  pd.json_normalize(meta_train ['categories'])\n",
    "images_train =  pd.json_normalize(meta_train ['images'])\n",
    "genera_train =  pd.json_normalize(meta_train ['genera'])\n",
    "distance_train =  pd.json_normalize(meta_train ['distances'])\n",
    "licenses_train =  pd.json_normalize(meta_train ['license'])\n",
    "institutions_train =  pd.json_normalize(meta_train ['institutions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#categories_train['species']=categories_train['species'].astype('category').cat.codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del genera_train\n",
    "del licenses_train\n",
    "del institutions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         000/test-000000.jpg\n",
      "1         000/test-000001.jpg\n",
      "2         000/test-000002.jpg\n",
      "3         000/test-000003.jpg\n",
      "4         000/test-000004.jpg\n",
      "                 ...         \n",
      "210402    223/test-223645.jpg\n",
      "210403    223/test-223646.jpg\n",
      "210404    223/test-223647.jpg\n",
      "210405    223/test-223648.jpg\n",
      "210406    223/test-223649.jpg\n",
      "Name: file_name, Length: 210407, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Looking at test set\n",
    "df_test = pd.DataFrame(meta_test)\n",
    "\n",
    "#creating test data\n",
    "df_test = df_test.drop(['license'], axis=1)\n",
    "\n",
    "print(df_test['file_name'])\n",
    "# adding file path\n",
    "df_test = df_test[['image_id','file_name']]\n",
    "df_test['file_path']='C:/Users/Steven/OneDrive - Cal State LA/Documents/image/'+df_test['file_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>genus_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00000__001</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>Abies</td>\n",
       "      <td>amabilis</td>\n",
       "      <td>Abies amabilis</td>\n",
       "      <td>000/00/00000__001.jpg</td>\n",
       "      <td>C:/Users/Steven/OneDrive - Cal State LA/Docume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00000__002</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>Abies</td>\n",
       "      <td>amabilis</td>\n",
       "      <td>Abies amabilis</td>\n",
       "      <td>000/00/00000__002.jpg</td>\n",
       "      <td>C:/Users/Steven/OneDrive - Cal State LA/Docume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00000__003</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>Abies</td>\n",
       "      <td>amabilis</td>\n",
       "      <td>Abies amabilis</td>\n",
       "      <td>000/00/00000__003.jpg</td>\n",
       "      <td>C:/Users/Steven/OneDrive - Cal State LA/Docume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00000__004</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>Abies</td>\n",
       "      <td>amabilis</td>\n",
       "      <td>Abies amabilis</td>\n",
       "      <td>000/00/00000__004.jpg</td>\n",
       "      <td>C:/Users/Steven/OneDrive - Cal State LA/Docume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00000__005</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>Abies</td>\n",
       "      <td>amabilis</td>\n",
       "      <td>Abies amabilis</td>\n",
       "      <td>000/00/00000__005.jpg</td>\n",
       "      <td>C:/Users/Steven/OneDrive - Cal State LA/Docume...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id  genus_id    image_id    family  genus   species  \\\n",
       "0            0         1  00000__001  Pinaceae  Abies  amabilis   \n",
       "1            0         1  00000__002  Pinaceae  Abies  amabilis   \n",
       "2            0         1  00000__003  Pinaceae  Abies  amabilis   \n",
       "3            0         1  00000__004  Pinaceae  Abies  amabilis   \n",
       "4            0         1  00000__005  Pinaceae  Abies  amabilis   \n",
       "\n",
       "             name              file_name  \\\n",
       "0  Abies amabilis  000/00/00000__001.jpg   \n",
       "1  Abies amabilis  000/00/00000__002.jpg   \n",
       "2  Abies amabilis  000/00/00000__003.jpg   \n",
       "3  Abies amabilis  000/00/00000__004.jpg   \n",
       "4  Abies amabilis  000/00/00000__005.jpg   \n",
       "\n",
       "                                           file_path  \n",
       "0  C:/Users/Steven/OneDrive - Cal State LA/Docume...  \n",
       "1  C:/Users/Steven/OneDrive - Cal State LA/Docume...  \n",
       "2  C:/Users/Steven/OneDrive - Cal State LA/Docume...  \n",
       "3  C:/Users/Steven/OneDrive - Cal State LA/Docume...  \n",
       "4  C:/Users/Steven/OneDrive - Cal State LA/Docume...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete df\n",
    "df_merge = pd.merge(images_train[['image_id','file_name']],annotations_train[['genus_id','category_id','image_id']] , on='image_id')\n",
    "df_merge = pd.merge(df_merge[['genus_id','image_id','file_name','category_id']],categories_train[['category_id','scientificName','family','genus','species']] , on='category_id')\n",
    "df_merge['file_path']='C:/Users/Steven/OneDrive - Cal State LA/Documents/images2/'+df_merge['file_name']\n",
    "df_merge['name']=df_merge['genus']+' '+df_merge['species']\n",
    "df_train = df_merge[['category_id','genus_id','image_id','family','genus','species','name','file_name','file_path']]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[11.66666667  1.66666667  4.66666667 ...  3.          1.\n",
      "  1.        ]\n",
      "0\n",
      "[4.         2.         2.         ... 2.         1.33333333 2.        ]\n",
      "0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0\n",
      "[52.66666667 57.66666667 55.66666667 ... 49.         47.66666667\n",
      " 48.66666667]\n",
      "0\n",
      "[66.66666667 60.66666667 57.33333333 ... 44.         50.\n",
      " 45.        ]\n",
      "0\n",
      "[105.66666667  94.33333333  78.         ...  45.66666667  43.66666667\n",
      "  45.66666667]\n",
      "1\n",
      "[ 1.66666667  5.66666667 10.66666667 ...  1.          3.\n",
      "  1.        ]\n",
      "1\n",
      "[5.33333333 4.66666667 4.66666667 ... 1.33333333 1.         1.66666667]\n",
      "1\n",
      "[4.         2.         6.66666667 ... 1.         2.         3.        ]\n",
      "1\n",
      "[44.         42.         35.         ... 28.         42.33333333\n",
      " 25.33333333]\n",
      "1\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "1\n",
      "[190.66666667 210.66666667 217.66666667 ...  54.          51.\n",
      "  51.        ]\n",
      "1\n",
      "[33.33333333 37.         47.         ... 30.         28.66666667\n",
      " 33.66666667]\n",
      "1\n",
      "[31.         39.         36.         ... 28.66666667 36.66666667\n",
      " 34.66666667]\n",
      "2\n",
      "[ 0.          3.          1.         ... 48.         55.33333333\n",
      " 72.33333333]\n",
      "2\n",
      "[56.33333333 59.33333333 62.33333333 ... 41.         49.\n",
      " 45.        ]\n",
      "2\n",
      "[155.         186.         187.33333333 ...  52.66666667  57.\n",
      "  52.        ]\n",
      "2\n",
      "[39. 39. 34. ... 19. 26. 25.]\n",
      "3\n",
      "[3.66666667 2.66666667 2.66666667 ... 0.33333333 2.         2.        ]\n",
      "3\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "3\n",
      "[61.         63.         62.         ... 58.66666667 56.\n",
      " 58.        ]\n",
      "3\n",
      "[63.66666667 63.66666667 67.         ... 58.         58.\n",
      " 56.        ]\n",
      "3\n",
      "[28.         32.         32.         ... 30.66666667 24.66666667\n",
      " 31.66666667]\n",
      "3\n",
      "[37. 43. 44. ... 22. 21. 25.]\n",
      "4\n",
      "[6.         6.33333333 5.33333333 ... 2.         0.33333333 1.        ]\n",
      "4\n",
      "[  0.66666667   0.66666667   1.66666667 ... 182.66666667 180.66666667\n",
      " 180.        ]\n",
      "4\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "4\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "4\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "4\n",
      "[56.33333333 54.33333333 62.33333333 ... 61.66666667 60.\n",
      " 62.        ]\n",
      "4\n",
      "[52.33333333 49.33333333 76.         ... 91.         92.33333333\n",
      " 89.33333333]\n",
      "4\n",
      "[31.         28.         29.         ... 21.66666667 24.66666667\n",
      " 21.66666667]\n",
      "5\n",
      "[ 6. 13.  5. ...  0.  1.  0.]\n",
      "5\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "5\n",
      "[ 64.66666667  61.66666667 206.         ...  96.66666667 101.\n",
      " 102.        ]\n",
      "5\n",
      "[27. 37. 24. ... 22. 23. 24.]\n",
      "5\n",
      "[24. 27. 21. ... 23. 22. 22.]\n",
      "5\n",
      "[21.         24.         23.         ... 24.66666667 23.33333333\n",
      " 22.33333333]\n",
      "5\n",
      "[111.33333333  99.33333333  77.33333333 ...  53.          45.33333333\n",
      "  42.66666667]\n",
      "6\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "6\n",
      "[68.         54.66666667 57.         ... 62.         54.33333333\n",
      " 60.66666667]\n",
      "6\n",
      "[ 44.33333333 164.33333333 159.66666667 ...  47.66666667  67.\n",
      "  66.        ]\n",
      "6\n",
      "[54. 45. 48. ... 30. 27. 25.]\n",
      "6\n",
      "[20.         19.         17.         ... 14.         14.66666667\n",
      " 14.        ]\n",
      "6\n",
      "[48.         48.         50.         ... 73.66666667 71.66666667\n",
      " 71.66666667]\n",
      "7\n",
      "[10.33333333  2.33333333  8.33333333 ...  1.          2.66666667\n",
      "  2.66666667]\n",
      "7\n",
      "[1.66666667 5.66666667 2.66666667 ... 1.         2.         2.        ]\n",
      "7\n",
      "[ 3.66666667  2.66666667  4.66666667 ... 13.66666667 12.66666667\n",
      " 10.66666667]\n",
      "7\n",
      "[ 61.33333333  63.          64.33333333 ... 159.         159.\n",
      " 161.        ]\n",
      "7\n",
      "[ 57.33333333  64.          53.         ... 116.66666667 114.\n",
      " 110.        ]\n",
      "(50, 626000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage.io import imread, imshow\n",
    "def makeimage(i2):\n",
    "    image=mpimg.imread(df_train['file_path'][i2])\n",
    "    print(df_train['category_id'][i2])\n",
    "    feature_matrix = np.zeros((1000,626) )\n",
    "    feature_matrix.shape\n",
    "\n",
    "    for i in range(0,image.shape[0]):\n",
    "        for j in range(0,626):\n",
    "            feature_matrix[i][j] = ((int(image[i,j,0]) + int(image[i,j,1]) + int(image[i,j,2]))/3)\n",
    "\n",
    "    features = np.reshape(feature_matrix, (image.shape[0]*626)) \n",
    "    features.shape\n",
    "\n",
    "    print(features)\n",
    "    return features\n",
    "\n",
    "\n",
    "i2=0\n",
    "img=[]\n",
    "while i2<500:\n",
    "    img.append(makeimage(i2))\n",
    "    i2=i2+10\n",
    "img=np.array(img)\n",
    "print(np.array(img).shape)\n",
    "#plt.imshow(img[2], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = categories_train['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 626000)\n",
      "[[-0.58974859 -0.79160445 -0.69875346 ... -0.78345242 -0.85468758\n",
      "  -0.84944083]\n",
      " [-0.78133359 -0.78441458 -0.75023649 ... -0.80848285 -0.84633776\n",
      "  -0.82446218]\n",
      " [-0.88129097 -0.82755379 -0.78884876 ... -0.85854371 -0.87973705\n",
      "  -0.87441949]\n",
      " ...\n",
      " [-0.78966337 -0.77003485 -0.69875346 ... -0.51646118 -0.56244388\n",
      "  -0.60798049]\n",
      " [ 0.65138898  0.53133123  0.45317939 ...  3.12129446  3.10312714\n",
      "   3.14714415]\n",
      " [ 0.55143159  0.55290084  0.2343765  ...  2.06167298  1.97590143\n",
      "   1.87323269]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X=preprocessing.scale(img)\n",
    "X\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16420/3224992194.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mscale\u001b[1;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \"\"\"  # noqa\n\u001b[1;32m--> 194\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    195\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "\n",
    "from  sklearn.decomposition  import  PCA\n",
    "\n",
    "k = 50  #  k  is the number of components (new features) after dimensionality reduction\n",
    "\n",
    "my_pca = PCA(n_components = k)\n",
    "\n",
    "# X_Train is feature matrix of training set before dimensionality reduction, \n",
    "\n",
    "# X_Train_New is feature matrix of training set after dimensionality reduction:\n",
    "\n",
    "X_train_new = my_pca. fit_transform(X_train)\n",
    "\n",
    "X_test_new = my_pca. transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "clf=svm.SVC(C=10, kernel='rbf', gamma=0.0005, random_state=1)\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train_new, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test_new)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000,5e3,1e4,5e4,1e5],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf'],\n",
    "             }\n",
    "\n",
    "X_normalized_pca = my_pca.fit_transform(X)\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid,  cv=10)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_normalized_pca, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
